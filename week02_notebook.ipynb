{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "eab6f10c",
            "metadata": {},
            "source": [
                "## 1. Environment Setup and Dependencies\n",
                "\n",
                "First, let's load our environment variables and import the required libraries. The `.env` file contains configuration settings that we'll use throughout this notebook."
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9278c5ff",
            "metadata": {},
            "source": [
                "# Install required packages (run this if packages are not already installed)\n",
                "%pip install python-dotenv requests lxml matplotlib drawsvg"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d268c921",
            "metadata": {},
            "source": [
                "# Import all required libraries\n",
                "import os\n",
                "import datetime\n",
                "import json\n",
                "import requests\n",
                "import dotenv\n",
                "from lxml import html\n",
                "import matplotlib.pyplot as plt\n",
                "import drawsvg as draw\n",
                "import re\n",
                "\n",
                "# Import our custom utilities\n",
                "from scraping_utils import get_url, parse\n",
                "\n",
                "print(\"All libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5f2cf0d3",
            "metadata": {},
            "source": [
                "# Load environment variables from .env file (force-reload and map new names to legacy names)\n",
                "from dotenv import dotenv_values, load_dotenv\n",
                "# Try to override existing env vars when supported\n",
                "try:\n",
                "    load_dotenv(override=True)\n",
                "except TypeError:\n",
                "    for k, v in dotenv_values('.env').items():\n",
                "        if v is not None:\n",
                "            os.environ[k] = v\n",
                "\n",
                "# Backwards compatibility: if the notebook expects YEAR/URL/etc but we have RAINFALL_URL/START_YEAR, map them\n",
                "# Map only when legacy names are not set to avoid overwriting explicit values\n",
                "if os.getenv('YEAR') is None and os.getenv('START_YEAR') is not None:\n",
                "    os.environ['YEAR'] = os.getenv('START_YEAR')\n",
                "if os.getenv('URL') is None and os.getenv('RAINFALL_URL') is not None:\n",
                "    # Keep legacy URL format using YEAR placeholder if needed\n",
                "    os.environ['URL'] = os.getenv('RAINFALL_URL')\n",
                "# ROW_XPATH/COL_XPATH may not be needed for the CSV flow; leave as-is unless provided\n",
                "# MULTICITY_URL fallback: map from MULTICITY_URL or leave None\n",
                "if os.getenv('MULTICITY_URL') is None and os.getenv('MULTICITY_URL') is None:\n",
                "    pass\n",
                "\n",
                "# Display the loaded and mapped environment variables\n",
                "print(\"Loaded environment variables (after mapping):\")\n",
                "print(f\"YEAR: {os.getenv('YEAR')}\")\n",
                "print(f\"URL: {os.getenv('URL')}\")\n",
                "print(f\"ROW_XPATH: {os.getenv('ROW_XPATH')}\")\n",
                "print(f\"COL_XPATH: {os.getenv('COL_XPATH')}\")\n",
                "print(f\"MULTICITY_URL: {os.getenv('MULTICITY_URL')}\")\n",
                "print(f\"RAINFALL_URL: {os.getenv('RAINFALL_URL')}\")\n",
                "print(f\"RAINFALL_STATION_NAME: {os.getenv('RAINFALL_STATION_NAME')}\")\n",
                "print(f\"START_YEAR: {os.getenv('START_YEAR')}\")\n",
                "print(f\"END_YEAR: {os.getenv('END_YEAR')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "89342464",
            "metadata": {},
            "source": [
                "## 2. Web Scraping Utilities\n",
                "\n",
                "Let's examine and demonstrate the utility functions we've created for web scraping. These functions help us fetch web pages and parse different data formats."
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ecfa802f",
            "metadata": {},
            "source": [
                "# Let's look at our scraping utilities\n",
                "import inspect\n",
                "\n",
                "print(\"get_url function:\")\n",
                "print(inspect.getsource(get_url))\n",
                "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
                "print(\"parse function:\")\n",
                "print(inspect.getsource(parse))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cf29ce5d",
            "metadata": {},
            "source": [
                "# Demonstrate the get_url function with a simple example\n",
                "# This will either fetch from the web or read from cache\n",
                "\n",
                "test_url = \"https://httpbin.org/json\"\n",
                "test_filename = \"test_page.html\"\n",
                "\n",
                "print(\"Fetching test page...\")\n",
                "page_content = get_url(test_url, test_filename)\n",
                "print(f\"Content length: {len(page_content)} characters\")\n",
                "print(f\"First 200 characters: {page_content[:200]}...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "54e0e7d5",
            "metadata": {},
            "source": [
                "# Demonstrate parsing JSON data\n",
                "json_data = parse(page_content, 'json')\n",
                "print(\"Parsed JSON data:\")\n",
                "print(json.dumps(json_data, indent=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "80f03127",
            "metadata": {},
            "source": [
                "## 3. HTML Data Extraction and Processing\n",
                "\n",
                "Now let's work with the actual HTML data that was scraped from the Hong Kong Observatory rainfall information."
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "685de990",
            "metadata": {},
            "source": [
                "# Load and examine the crawled HTML page\n",
                "year = int(os.getenv('YEAR', 2024))\n",
                "filename = os.getenv('FILENAME', \"crawled-page-{year}.html\").format(year=year)\n",
                "\n",
                "print(f\"Loading HTML file: {filename}\")\n",
                "\n",
                "# Check if the file exists\n",
                "if os.path.exists(filename):\n",
                "    with open(filename, 'r', encoding='UTF8') as f:\n",
                "        html_content = f.read()\n",
                "    \n",
                "    print(f\"HTML file loaded successfully!\")\n",
                "    print(f\"Content length: {len(html_content)} characters\")\n",
                "    print(f\"First 500 characters:\\n{html_content[:500]}...\")\n",
                "else:\n",
                "    print(f\"HTML file {filename} not found. Let's fetch it from the web.\")\n",
                "    \n",
                "    # Use environment variable URL and YEAR for Hong Kong rainfall 2024\n",
                "    url = os.getenv('URL').replace('${YEAR}', str(year))\n",
                "    print(f\"Fetching from: {url}\")\n",
                "    \n",
                "    html_content = get_url(url, filename)\n",
                "    print(f\"Content fetched and saved to {filename}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "85fd4b37",
            "metadata": {},
            "source": [
                "# Parse the HTML content\n",
                "tree = parse(html_content, 'html')\n",
                "\n",
                "# Extract table structure using XPath\n",
                "# Use fallback XPath if environment variables are not set\n",
                "row_xpath = os.getenv('ROW_XPATH')\n",
                "col_xpath = os.getenv('COL_XPATH')\n",
                "if row_xpath is None:\n",
                "    # Fallback: select all <tr> elements\n",
                "    row_xpath = '//tr'\n",
                "if col_xpath is None:\n",
                "    # Fallback: select all <td> and <th> elements within a row\n",
                "    col_xpath = './td | ./th'\n",
                "\n",
                "rows = tree.xpath(row_xpath)\n",
                "print(f\"Found {len(rows)} rows in the HTML table\")\n",
                "\n",
                "# Examine the first few rows\n",
                "print(\"\\nFirst 3 rows structure:\")\n",
                "for i, row in enumerate(rows[:3]):\n",
                "    columns = row.xpath(os.getenv('COL_XPATH'))\n",
                "    column_texts = [col.text_content().strip() for col in columns]\n",
                "    print(f\"Row {i+1}: {column_texts}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "491f93cb",
            "metadata": {},
            "source": [
                "## 4. CSV Data Handling for Rainfall\n",
                "\n",
                "Let's process the rainfall data and create a CSV file, then load and analyze the data."
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e8a9fab2",
            "metadata": {},
            "source": [
                "# Process rainfall and humidity data\n",
                "# We'll attempt to extract both rainfall (mm) and humidity (%) when available\n",
                "data = []  # list of tuples: (datetime, rainfall_mm_or_None, humidity_pct_or_None)\n",
                "row_num = 0\n",
                "\n",
                "print(\"Processing rainfall and humidity data...\")\n",
                "\n",
                "for row in tree.xpath(row_xpath):\n",
                "    columns = row.xpath(col_xpath)\n",
                "    columns = [column.text_content().strip() if column.text_content() is not None else '' for column in columns]\n",
                "    row_string = \" \".join(columns).strip()\n",
                "    \n",
                "    # Skip empty rows\n",
                "    if row_string == \"\":\n",
                "        continue\n",
                "    \n",
                "    row_num += 1\n",
                "    \n",
                "    # Only log first few rows for demonstration\n",
                "    if row_num <= 5:\n",
                "        print(f'Row {row_num}: {row_string}')\n",
                "    \n",
                "    # Skip header or invalid rows\n",
                "    if len(columns) < 3 or not columns[0].lstrip('0').isdigit():\n",
                "        continue\n",
                "    \n",
                "    try:\n",
                "        month = int(columns[0])\n",
                "        day = int(columns[1])\n",
                "        \n",
                "        # Iterate through the remaining columns trying to pair time, rainfall and possibly humidity\n",
                "        # Common layouts: [MM, DD, HHMM, mm, HHMM, mm, ...] or sometimes humidity appears nearby like '45%'\n",
                "        for i in range(2, len(columns)):\n",
                "            col = columns[i]\n",
                "            # Identify time-like entries (HHMM or HMM)\n",
                "            time_digits = re.sub(r'[^0-9]', '', col)\n",
                "            if len(time_digits) >= 3 and len(time_digits) <= 4:\n",
                "                # Normalize to HHMM if needed\n",
                "                if len(time_digits) == 3:\n",
                "                    time_digits = '0' + time_digits\n",
                "                if not time_digits.isdigit():\n",
                "                    continue\n",
                "                hour = int(time_digits[:2])\n",
                "                minute = int(time_digits[2:])\n",
                "                # Build datetime, guard against invalid hours/minutes\n",
                "                try:\n",
                "                    dt = datetime.datetime(year, month, day, hour, minute)\n",
                "                except ValueError:\n",
                "                    continue\n",
                "                # Attempt to read next columns for rainfall and humidity\n",
                "                rainfall = None\n",
                "                humidity = None\n",
                "                # Next column often contains rainfall amount\n",
                "                if i+1 < len(columns):\n",
                "                    next_col = columns[i+1]\n",
                "                    # Extract numeric rainfall value (allow decimal)\n",
                "                    val = re.sub(r'[^0-9.]', '', next_col)\n",
                "                    if val != '':\n",
                "                        try:\n",
                "                            rainfall = float(val)\n",
                "                        except ValueError:\n",
                "                            rainfall = None\n",
                "                # Look ahead one more column for humidity if present (e.g., '45%')\n",
                "                if i+2 < len(columns):\n",
                "                    maybe_hum = columns[i+2]\n",
                "                    hum_digits = re.sub(r'[^0-9.]', '', maybe_hum)\n",
                "                    if hum_digits != '':\n",
                "                        try:\n",
                "                            humidity = float(hum_digits)\n",
                "                        except ValueError:\n",
                "                            humidity = None\n",
                "                # As a fallback, search the same row for any value containing '%'\n",
                "                if humidity is None:\n",
                "                    for c in columns:\n",
                "                        if '%' in c:\n",
                "                            h = re.sub(r'[^0-9.]', '', c)\n",
                "                            if h != '':\n",
                "                                try:\n",
                "                                    humidity = float(h)\n",
                "                                    break\n",
                "                                except ValueError:\n",
                "                                    continue\n",
                "                # Append record only if we have at least rainfall or humidity\n",
                "                if rainfall is not None or humidity is not None:\n",
                "                    data.append((dt, rainfall, humidity))\n",
                "                    if len(data) <= 10:\n",
                "                        print(f'{dt} - rainfall={rainfall} mm, humidity={humidity} %')\n",
                "    except (ValueError, IndexError) as e:\n",
                "        # Skip problematic rows\n",
                "        continue\n",
                "\n",
                "print(f\"\\nProcessed {len(data)} rainfall/humidity data points\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8344a2a7",
            "metadata": {},
            "source": [
                "# Create CSV file for rainfall and humidity\n",
                "csv_filename = 'rainfall_processed.csv'\n",
                "\n",
                "print(f\"Creating CSV file: {csv_filename}\")\n",
                "\n",
                "with open(csv_filename, 'w') as f:\n",
                "    f.write('datetime,rainfall_mm,humidity_pct\\n')  # Header\n",
                "    for record in data:\n",
                "        dt_str = record[0].strftime(\"%Y-%m-%d %H:%M\")\n",
                "        rainfall_val = '' if record[1] is None else f'{record[1]:.2f}'\n",
                "        humidity_val = '' if record[2] is None else f'{record[2]:.1f}'\n",
                "        f.write(f'{dt_str},{rainfall_val},{humidity_val}\\n')\n",
                "\n",
                "print(f\"CSV file created with {len(data)} records\")\n",
                "\n",
                "# Read and display first few lines of the CSV\n",
                "with open(csv_filename, 'r') as f:\n",
                "    lines = f.readlines()[:10]\n",
                "    print(\"\\nFirst 10 lines of CSV:\")\n",
                "    for line in lines:\n",
                "        print(line.strip())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6500653b",
            "metadata": {},
            "source": [
                "## 5. Daily Mean Wind Speed All Year - Kai Tak\n",
                "\n",
                "We'll fetch the Hong Kong Observatory daily wind CSV and extract the daily mean wind speed for the Kai Tak (KaiTak) station.\n",
                "\n",
                "The notebook will look for environment variables `WIND_URL` and `WIND_STATION_NAME`. If they are not present, it will fall back to sensible defaults and the previously used `RAINFALL_` variables where appropriate."
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "faea1581",
            "metadata": {},
            "source": [
                "# Daily Mean Wind Speed for Kai Tak (from HKO CSV)\n",
                "# Environment variables: WIND_URL, WIND_STATION_NAME, START_YEAR, END_YEAR\n",
                "wind_url = os.getenv('WIND_URL') or os.getenv('RAINFALL_URL') or 'https://data.weather.gov.hk/cis/csvfile/SE/ALL/daily_SE_WSPD_ALL.csv'\n",
                "wind_station = os.getenv('WIND_STATION_NAME') or os.getenv('RAINFALL_STATION_NAME') or 'KaiTak'\n",
                "start_year = int(os.getenv('START_YEAR', 2010))\n",
                "end_year = int(os.getenv('END_YEAR', 2025))\n",
                "\n",
                "print(f\"Fetching wind CSV from: {wind_url}\")\n",
                "print(f\"Filtering station: {wind_station}\")\n",
                "\n",
                "# Download the CSV (uses caching behavior of get_url if implemented)\n",
                "csv_filename = 'daily_SE_WSPD_ALL.csv'\n",
                "csv_text = get_url(wind_url, csv_filename)\n",
                "\n",
                "# Parse CSV lines\n",
                "lines = csv_text.splitlines()\n",
                "header = lines[0] if lines else ''\n",
                "print(f\"CSV header: {header[:200]}\")\n",
                "\n",
                "import csv\n",
                "reader = csv.DictReader(lines)\n",
                "\n",
                "# kai_tak_data will be list of dicts: {'date': date_obj, 'mean_wspd': float_or_None, 'station': station_name}\n",
                "kai_tak_data = []\n",
                "\n",
                "for row in reader:\n",
                "    # HKO CSV typically contains a 'station' or 'Station' field and date fields like 'yyyy-mm-dd' or 'date'\n",
                "    # We'll perform a case-insensitive check for the station name in any of the station-like fields\n",
                "    station_fields = [k for k in row.keys() if 'station' in k.lower() or 'stn' in k.lower()]\n",
                "    station_val = None\n",
                "    for sf in station_fields:\n",
                "        if row.get(sf):\n",
                "            station_val = row.get(sf).strip()\n",
                "            break\n",
                "    # Some CSVs include station as a separate column, others include station in a combined column; fallback to searching all values\n",
                "    if station_val is None:\n",
                "        # look for exact station name anywhere in the row values\n",
                "        for v in row.values():\n",
                "            if v and wind_station.lower() in v.lower():\n",
                "                station_val = v.strip()\n",
                "                break\n",
                "    if station_val is None:\n",
                "        continue\n",
                "    # Parse date: try common column names\n",
                "    date_str = None\n",
                "    for date_key in ['date', 'Date', 'obs_time', 'yyyy-mm-dd', 'yyyymmdd']:\n",
                "        if date_key in row and row[date_key]:\n",
                "            date_str = row[date_key].strip()\n",
                "            break\n",
                "    if date_str is None:\n",
                "        # attempt to find a field that looks like a date\n",
                "        for k, v in row.items():\n",
                "            if v and re.match(r'\\d{4}-\\d{2}-\\d{2}', v):\n",
                "                date_str = v.strip()\n",
                "                break\n",
                "    if date_str is None:\n",
                "        continue\n",
                "    # Parse mean wind speed value: look for 'mean', 'avg', 'wspd' in column names\n",
                "    wspd_fields = [k for k in row.keys() if any(x in k.lower() for x in ['mean', 'avg', 'wspd', 'w_speed', 'wind'])]\n",
                "    wspd_val = None\n",
                "    for wf in wspd_fields:\n",
                "        v = row.get(wf)\n",
                "        if v and v.strip() != '':\n",
                "            # strip non-numeric characters\n",
                "            num = re.sub(r'[^0-9\\.]', '', v)\n",
                "            if num != '':\n",
                "                try:\n",
                "                    wspd_val = float(num)\n",
                "                    break\n",
                "                except ValueError:\n",
                "                    wspd_val = None\n",
                "    # fallback: check common column names explicitly\n",
                "    if wspd_val is None:\n",
                "        for explicit in ['MeanWindSpeed', 'MEAN_WSPD', 'Mean_Wspd', 'WSPD']:\n",
                "            if explicit in row and row[explicit].strip() != '':\n",
                "                num = re.sub(r'[^0-9\\.]', '', row[explicit])\n",
                "                if num != '':\n",
                "                    try:\n",
                "                        wspd_val = float(num)\n",
                "                        break\n",
                "                    except ValueError:\n",
                "                        wspd_val = None\n",
                "    # Parse the date into a datetime.date where possible\n",
                "    try:\n",
                "        date_obj = datetime.datetime.strptime(date_str[:10], '%Y-%m-%d').date()\n",
                "    except Exception:\n",
                "        # skip unparsable dates\n",
                "        continue\n",
                "    # Filter by year range\n",
                "    if date_obj.year < start_year or date_obj.year > end_year:\n",
                "        continue\n",
                "    # Match station name loosely (case-insensitive substring)\n",
                "    if station_val is not None and wind_station.lower() in station_val.lower():\n",
                "        kai_tak_data.append({'date': date_obj, 'mean_wspd': wspd_val, 'station': station_val})\n",
                "\n",
                "print(f\"Found {len(kai_tak_data)} records for station '{wind_station}' between {start_year} and {end_year}\")\n",
                "if kai_tak_data:\n",
                "    print('Sample records (first 10):')\n",
                "    for r in kai_tak_data[:10]:\n",
                "        print(r)\n",
                "else:\n",
                "    print('No matching records found. Check WIND_URL and WIND_STATION_NAME environment variables.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12927dd8",
            "metadata": {},
            "source": [
                "# Prefer the locally generated CSV if it exists to avoid re-downloading the whole HKO file\n",
                "local_csv = f'kaitak_wind_{start_year}_{end_year}.csv'\n",
                "kai_tak_data = []\n",
                "if os.path.exists(local_csv):\n",
                "    print(f'Loading local processed CSV: {local_csv}')\n",
                "    import csv\n",
                "    with open(local_csv, 'r') as f:\n",
                "        rdr = csv.DictReader(f)\n",
                "        for row in rdr:\n",
                "            try:\n",
                "                d = datetime.datetime.strptime(row['date'], '%Y-%m-%d').date()\n",
                "            except Exception:\n",
                "                continue\n",
                "            val = row.get('mean_wspd')\n",
                "            wspd = float(val) if val not in (None, '') else None\n",
                "            kai_tak_data.append({'date': d, 'mean_wspd': wspd, 'station': row.get('station')})\n",
                "else:\n",
                "    print('Local processed CSV not found; falling back to parsing the fetched HKO CSV')\n",
                "    # At this point `reader` and `lines` may be available from the previous cell; if not, re-fetch\n",
                "    try:\n",
                "        reader\n",
                "    except NameError:\n",
                "        csv_text = get_url(wind_url, 'daily_SE_WSPD_ALL.csv')\n",
                "        lines = csv_text.splitlines()\n",
                "        header = lines[0] if lines else ''\n",
                "        import csv\n",
                "        reader = csv.DictReader(lines)\n",
                "    # Fallback parsing: scan DictReader rows for station and wind speed data\n",
                "    kai_tak_data = []\n",
                "    for row in reader:\n",
                "        # attempt to build date and value from common dict fields\n",
                "        date_str = row.get('date') or row.get('Date') or row.get('yyyy-mm-dd') or ''\n",
                "        if not date_str:\n",
                "            # try Year,Month,Day fields\n",
                "            try:\n",
                "                y = int(row.get('Year', '0'))\n",
                "                m = int(row.get('Month', '0'))\n",
                "                d = int(row.get('Day', '0'))\n",
                "                date_obj = datetime.date(y, m, d)\n",
                "            except Exception:\n",
                "                continue\n",
                "        else:\n",
                "            try:\n",
                "                date_obj = datetime.datetime.strptime(date_str[:10], '%Y-%m-%d').date()\n",
                "            except Exception:\n",
                "                continue\n",
                "        v = row.get('Value') or row.get('value') or row.get('mean_wspd') or ''\n",
                "        wspd = None\n",
                "        if v not in (None, ''):\n",
                "            try:\n",
                "                wspd = float(re.sub(r'[^0-9\\.-]', '', v))\n",
                "            except Exception:\n",
                "                wspd = None\n",
                "        # check station cell\n",
                "        station_val = row.get('station') or row.get('Station') or ''\n",
                "        if station_val and wind_station.lower() in station_val.lower():\n",
                "            kai_tak_data.append({'date': date_obj, 'mean_wspd': wspd, 'station': station_val})\n",
                "\n",
                "print(f'Loaded kai_tak_data records: {len(kai_tak_data)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5043a5f",
            "metadata": {},
            "source": [
                "# Display summary of Kai Tak daily mean wind speed data\n",
                "if kai_tak_data:\n",
                "    print(\"Summary of Kai Tak wind data:\")\n",
                "    # Show basic stats\n",
                "    speeds = [r['mean_wspd'] for r in kai_tak_data if r['mean_wspd'] is not None]\n",
                "    dates = [r['date'] for r in kai_tak_data]\n",
                "    print(f\"Records: {len(kai_tak_data)} (with numeric wind speeds: {len(speeds)})\")\n",
                "    if speeds:\n",
                "        print(f\"Mean wind speed: {sum(speeds)/len(speeds):.2f} (units as in source)\")\n",
                "        print(f\"Min: {min(speeds):.2f}, Max: {max(speeds):.2f}\")\n",
                "    print('Sample (first 10)')\n",
                "    for r in kai_tak_data[:10]:\n",
                "        print(f\"  {r['date']} - {r['station']} - mean_wspd={r['mean_wspd']}\")\n",
                "else:\n",
                "    print(\"No Kai Tak wind data was successfully fetched.\")\n",
                "    print(\"Check WIND_URL, WIND_STATION_NAME, and network connectivity.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "13f51137",
            "metadata": {},
            "source": [
                "# Plot Kai Tak daily mean wind speed (if available)\n",
                "if 'kai_tak_data' in globals() and kai_tak_data:\n",
                "    import matplotlib.pyplot as plt\n",
                "    # Time series (only numeric values)\n",
                "    numeric = [r for r in kai_tak_data if r['mean_wspd'] is not None]\n",
                "    if numeric:\n",
                "        dates = [r['date'] for r in numeric]\n",
                "        speeds = [r['mean_wspd'] for r in numeric]\n",
                "        plt.figure(figsize=(12, 4))\n",
                "        plt.plot(dates, speeds, '-o', markersize=3)\n",
                "        plt.title('Kai Tak - Daily Mean Wind Speed')\n",
                "        plt.xlabel('Date')\n",
                "        plt.ylabel('Mean Wind Speed')\n",
                "        plt.grid(alpha=0.3)\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "        # Histogram\n",
                "        plt.figure(figsize=(8, 4))\n",
                "        plt.hist(speeds, bins=30, edgecolor='black', alpha=0.7)\n",
                "        plt.title('Distribution of Daily Mean Wind Speed - Kai Tak')\n",
                "        plt.xlabel('Mean Wind Speed')\n",
                "        plt.ylabel('Frequency')\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "    else:\n",
                "        print('No numeric mean wind speed values to plot')\n",
                "else:\n",
                "    print('kai_tak_data not found or empty. Run the previous cell to fetch data first.')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7f130235",
            "metadata": {},
            "source": [
                "## 6. Rainfall Data Visualization\n",
                "\n",
                "Now let's create visualizations of our rainfall data using matplotlib."
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3a614ca3",
            "metadata": {},
            "source": [
                "# Prepare data for plotting (rainfall and humidity)\n",
                "if data:\n",
                "    plot_data = []  # list of (dt, rainfall_float_or_None, humidity_float_or_None)\n",
                "    for dt, rainfall, humidity in data:\n",
                "        # rainfall and humidity are already numeric or None\n",
                "        plot_data.append((dt, rainfall, humidity))\n",
                "    \n",
                "    print(f\"Prepared {len(plot_data)} data points for plotting\")\n",
                "    \n",
                "    # Separate series\n",
                "    dates = [p[0] for p in plot_data]\n",
                "    rainfall_values = [p[1] for p in plot_data]\n",
                "    humidity_values = [p[2] for p in plot_data]\n",
                "    \n",
                "    # Compute ranges where data exists\n",
                "    valid_rain = [v for v in rainfall_values if v is not None]\n",
                "    valid_hum = [h for h in humidity_values if h is not None]\n",
                "    if valid_rain:\n",
                "        print(f\"Rainfall range: {min(valid_rain):.2f} mm to {max(valid_rain):.2f} mm\")\n",
                "    if valid_hum:\n",
                "        print(f\"Humidity range: {min(valid_hum):.1f}% to {max(valid_hum):.1f}%\")\n",
                "else:\n",
                "    print(\"No rainfall/humidity data available for plotting\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1416a568",
            "metadata": {},
            "source": [
                "# Create rainfall/humidity visualization\n",
                "if 'plot_data' in locals() and plot_data:\n",
                "    # Determine if we have rainfall and/or humidity\n",
                "    has_rain = any(v is not None for v in rainfall_values)\n",
                "    has_hum = any(h is not None for h in humidity_values)\n",
                "    \n",
                "    if has_rain and has_hum:\n",
                "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
                "        ax1.plot(dates, rainfall_values, 'b-', linewidth=1.5, alpha=0.8)\n",
                "        ax1.set_ylabel('Rainfall (mm)')\n",
                "        ax1.set_title(f'Hong Kong Rainfall and Humidity - {year}')\n",
                "        ax1.grid(True, alpha=0.3)\n",
                "        \n",
                "        ax2.plot(dates, humidity_values, 'g-', linewidth=1.5, alpha=0.8)\n",
                "        ax2.set_ylabel('Humidity (%)')\n",
                "        ax2.set_xlabel('Date and Time')\n",
                "        ax2.grid(True, alpha=0.3)\n",
                "        plt.xticks(rotation=45)\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "    elif has_rain:\n",
                "        plt.figure(figsize=(12, 6))\n",
                "        plt.plot(dates, rainfall_values, 'b-', linewidth=1.5, alpha=0.8)\n",
                "        plt.title(f'Hong Kong Rainfall - {year}', fontsize=14, fontweight='bold')\n",
                "        plt.xlabel('Date and Time')\n",
                "        plt.ylabel('Rainfall (mm)')\n",
                "        plt.grid(True, alpha=0.3)\n",
                "        plt.xticks(rotation=45)\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "    elif has_hum:\n",
                "        plt.figure(figsize=(12, 6))\n",
                "        plt.plot(dates, humidity_values, 'g-', linewidth=1.5, alpha=0.8)\n",
                "        plt.title(f'Hong Kong Humidity - {year}', fontsize=14, fontweight='bold')\n",
                "        plt.xlabel('Date and Time')\n",
                "        plt.ylabel('Humidity (%)')\n",
                "        plt.grid(True, alpha=0.3)\n",
                "        plt.xticks(rotation=45)\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "    else:\n",
                "        print(\"No numeric rainfall or humidity values available to plot\")\n",
                "else:\n",
                "    print(\"Creating sample visualizations as no real data is available\")\n",
                "    import numpy as np\n",
                "    sample_times = [datetime.datetime(2023, 1, 1) + datetime.timedelta(hours=i) for i in range(48)]\n",
                "    sample_rain = [0.0 if i%6 else 5.0 for i in range(48)]\n",
                "    sample_hum = [60 + 10 * np.sin(2 * np.pi * i / 24) for i in range(48)]\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    plt.plot(sample_times, sample_rain, 'b-', linewidth=2)\n",
                "    plt.title('Sample Rainfall Data Visualization', fontsize=16, fontweight='bold')\n",
                "    plt.xlabel('Time')\n",
                "    plt.ylabel('Rainfall (mm)')\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    plt.xticks(rotation=45)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    plt.figure(figsize=(12, 6))\n",
                "    plt.plot(sample_times, sample_hum, 'g-', linewidth=2)\n",
                "    plt.title('Sample Humidity Data Visualization', fontsize=16, fontweight='bold')\n",
                "    plt.xlabel('Time')\n",
                "    plt.ylabel('Humidity (%)')\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    plt.xticks(rotation=45)\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c9d554df",
            "metadata": {},
            "source": [
                "# Create additional visualization styles (rainfall & humidity)\n",
                "if 'plot_data' in locals() and plot_data and len(plot_data) > 10:\n",
                "    # Prepare series (allow None values)\n",
                "    rainfall_values = [p[1] for p in plot_data]\n",
                "    humidity_values = [p[2] for p in plot_data]\n",
                "    has_rain = any(v is not None for v in rainfall_values)\n",
                "    has_hum = any(h is not None for h in humidity_values)\n",
                "    \n",
                "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
                "    \n",
                "    # Top-left: Line plot of rainfall (if available)\n",
                "    if has_rain:\n",
                "        axes[0, 0].plot(dates, rainfall_values, 'b-', alpha=0.7)\n",
                "        axes[0, 0].set_title('Rainfall Over Time')\n",
                "        axes[0, 0].set_ylabel('Rainfall (mm)')\n",
                "    else:\n",
                "        axes[0, 0].text(0.5, 0.5, 'No rainfall data', ha='center', va='center')\n",
                "        axes[0, 0].set_title('Rainfall Over Time')\n",
                "    axes[0, 0].grid(True, alpha=0.3)\n",
                "    \n",
                "    # Top-right: Scatter rainfall vs humidity (if humidity present), else scatter rainfall over time\n",
                "    if has_hum:\n",
                "        # Scatter: rainfall vs humidity (only plot pairs where both exist)\n",
                "        x = [r for r, h in zip(rainfall_values, humidity_values) if r is not None and h is not None]\n",
                "        y = [h for r, h in zip(rainfall_values, humidity_values) if r is not None and h is not None]\n",
                "        if x and y:\n",
                "            axes[0, 1].scatter(x, y, alpha=0.6, s=20)\n",
                "            axes[0, 1].set_xlabel('Rainfall (mm)')\n",
                "            axes[0, 1].set_ylabel('Humidity (%)')\n",
                "            axes[0, 1].set_title('Rainfall vs Humidity')\n",
                "        else:\n",
                "            axes[0, 1].text(0.5, 0.5, 'No paired rainfall/humidity samples', ha='center', va='center')\n",
                "            axes[0, 1].set_title('Rainfall vs Humidity')\n",
                "    else:\n",
                "        # Fallback: scatter rainfall over time if humidity not available\n",
                "        if has_rain:\n",
                "            axes[0, 1].scatter(dates, rainfall_values, alpha=0.6, s=10)\n",
                "            axes[0, 1].set_title('Rainfall Scatter')\n",
                "            axes[0, 1].set_ylabel('Rainfall (mm)')\n",
                "        else:\n",
                "            axes[0, 1].text(0.5, 0.5, 'No data', ha='center', va='center')\n",
                "            axes[0, 1].set_title('Rainfall Scatter')\n",
                "    axes[0, 1].grid(True, alpha=0.3)\n",
                "    \n",
                "    # Bottom-left: Histogram of rainfall (or humidity if rainfall missing)\n",
                "    if has_rain:\n",
                "        valid_rain = [v for v in rainfall_values if v is not None]\n",
                "        axes[1, 0].hist(valid_rain, bins=20, alpha=0.7, edgecolor='black')\n",
                "        axes[1, 0].set_title('Rainfall Distribution')\n",
                "        axes[1, 0].set_xlabel('Rainfall (mm)')\n",
                "        axes[1, 0].set_ylabel('Frequency')\n",
                "    elif has_hum:\n",
                "        valid_hum = [h for h in humidity_values if h is not None]\n",
                "        axes[1, 0].hist(valid_hum, bins=20, alpha=0.7, edgecolor='black', color='green')\n",
                "        axes[1, 0].set_title('Humidity Distribution')\n",
                "        axes[1, 0].set_xlabel('Humidity (%)')\n",
                "        axes[1, 0].set_ylabel('Frequency')\n",
                "    else:\n",
                "        axes[1, 0].text(0.5, 0.5, 'No numeric data', ha='center', va='center')\n",
                "    \n",
                "    # Bottom-right: Box plot(s)\n",
                "    box_data = []\n",
                "    labels = []\n",
                "    if has_rain:\n",
                "        box_data.append([v for v in rainfall_values if v is not None])\n",
                "        labels.append('Rainfall (mm)')\n",
                "    if has_hum:\n",
                "        box_data.append([h for h in humidity_values if h is not None])\n",
                "        labels.append('Humidity (%)')\n",
                "    if box_data:\n",
                "        axes[1, 1].boxplot(box_data, labels=labels)\n",
                "        axes[1, 1].set_title('Box Plot')\n",
                "    else:\n",
                "        axes[1, 1].text(0.5, 0.5, 'No numeric data', ha='center', va='center')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"Not enough data for multiple visualizations\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "71b64f5c",
            "metadata": {},
            "source": [
                "## 7. SVG Drawing and Graphics\n",
                "\n",
                "Finally, let's explore programmatic graphics creation using SVG. This demonstrates how we can create vector graphics using code."
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "befd2b55",
            "metadata": {},
            "source": [
                "# Create a basic SVG drawing (from draw_svg.py)\n",
                "d = draw.Drawing(200, 100, origin='center')\n",
                "\n",
                "# Draw an irregular polygon\n",
                "d.append(draw.Lines(-80, 45,\n",
                "                     70, 49,\n",
                "                     95, -49,\n",
                "                    -90, -40,\n",
                "                    close=False,\n",
                "            fill='#eeee00',\n",
                "            stroke='black'))\n",
                "\n",
                "# Save the SVG\n",
                "svg_filename = 'irregular-polygon.svg'\n",
                "d.save_svg(svg_filename)\n",
                "print(f\"SVG saved as: {svg_filename}\")\n",
                "\n",
                "# Display the SVG as text\n",
                "print(\"\\nSVG content:\")\n",
                "print(d.as_svg())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b68a17da",
            "metadata": {},
            "source": [
                "# Create more complex SVG graphics\n",
                "# Example 1: Geometric shapes\n",
                "d2 = draw.Drawing(400, 300, origin='center')\n",
                "\n",
                "# Add a rectangle\n",
                "d2.append(draw.Rectangle(-150, -100, 100, 80, fill='lightblue', stroke='navy', stroke_width=2))\n",
                "\n",
                "# Add a circle\n",
                "d2.append(draw.Circle(50, 0, 40, fill='red', stroke='darkred', stroke_width=2))\n",
                "\n",
                "# Add some text\n",
                "d2.append(draw.Text('Week 02 Graphics', 20, -120, -50, fill='black', font_family='Arial', font_weight='bold'))\n",
                "\n",
                "# Add lines\n",
                "d2.append(draw.Line(-100, 50, 100, 50, stroke='green', stroke_width=3))\n",
                "d2.append(draw.Line(0, -80, 0, 80, stroke='purple', stroke_width=2, stroke_dasharray='5,5'))\n",
                "\n",
                "# Save and display\n",
                "geometric_svg = 'geometric-shapes.svg'\n",
                "d2.save_svg(geometric_svg)\n",
                "print(f\"Geometric shapes SVG saved as: {geometric_svg}\")\n",
                "print(f\"SVG dimensions: {d2.width} x {d2.height}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ad1ef857",
            "metadata": {},
            "source": [
                "# Example 2: Data visualization in SVG\n",
                "# Create a simple bar chart of tide statistics\n",
                "\n",
                "# Define values as an empty list to use sample data branch\n",
                "values = []\n",
                "\n",
                "d3 = draw.Drawing(500, 300, origin=(0, 0))\n",
                "\n",
                "# Sample data for visualization\n",
                "if 'values' in locals() and values:\n",
                "    # Use actual tide data\n",
                "    stats = {\n",
                "        'Max': max(values),\n",
                "        'Min': abs(min(values)),  # Use absolute value for visualization\n",
                "        'Avg': sum(values)/len(values)\n",
                "    }\n",
                "else:\n",
                "    # Use sample data\n",
                "    stats = {'Max': 3.2, 'Min': 0.5, 'Avg': 1.8}\n",
                "\n",
                "# Draw title\n",
                "d3.append(draw.Text('Sample Statistics', 24, 250, 30, text_anchor='middle', \n",
                "                   fill='black', font_family='Arial', font_weight='bold'))\n",
                "\n",
                "# Draw bars\n",
                "bar_width = 60\n",
                "bar_spacing = 100\n",
                "start_x = 100\n",
                "start_y = 250\n",
                "max_height = 150\n",
                "scale = max_height / max(stats.values())\n",
                "\n",
                "colors = ['#ff6b6b', '#4ecdc4', '#45b7d1']\n",
                "\n",
                "for i, (label, value) in enumerate(stats.items()):\n",
                "    x = start_x + i * bar_spacing\n",
                "    height = value * scale\n",
                "    \n",
                "    # Draw bar\n",
                "    d3.append(draw.Rectangle(x, start_y - height, bar_width, height,\n",
                "                           fill=colors[i], stroke='black', stroke_width=1))\n",
                "    \n",
                "    # Draw label\n",
                "    d3.append(draw.Text(label, 14, x + bar_width/2, start_y + 20,\n",
                "                       text_anchor='middle', fill='black'))\n",
                "    \n",
                "    # Draw value\n",
                "    d3.append(draw.Text(f'{value:.1f}m', 12, x + bar_width/2, start_y - height - 10,\n",
                "                       text_anchor='middle', fill='black', font_weight='bold'))\n",
                "\n",
                "# Save the chart\n",
                "chart_svg = 'sample-chart.svg'\n",
                "d3.save_svg(chart_svg)\n",
                "print(f\"Sample statistics chart saved as: {chart_svg}\")\n",
                "print(f\"Chart shows: {stats}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7cdb436c",
            "metadata": {},
            "source": [
                "## Summary and Key Takeaways\n",
                "\n",
                "In this Week 02 notebook, we have covered:\n",
                "\n",
                "### 1. **Environment Management**\n",
                "- Used `.env` files to store configuration\n",
                "- Loaded environment variables with `python-dotenv`\n",
                "- Managed sensitive data and configuration separately from code\n",
                "\n",
                "### 2. **Web Scraping Techniques**\n",
                "- Created reusable utility functions for web scraping\n",
                "- Implemented caching to avoid repeated requests\n",
                "- Handled both HTML and JSON data formats\n",
                "\n",
                "### 3. **Data Processing**\n",
                "- Parsed HTML using XPath selectors\n",
                "- Extracted structured data from web pages\n",
                "- Converted data to CSV format for further analysis\n",
                "- Handled date/time data and numeric conversions\n",
                "\n",
                "### 4. **Data Visualization**\n",
                "- Created multiple types of plots with matplotlib\n",
                "- Displayed time-series data effectively\n",
                "- Generated statistical summaries and distributions\n",
                "\n",
                "### 5. **Programmatic Graphics**\n",
                "- Created vector graphics with SVG\n",
                "- Generated geometric shapes and text\n",
                "- Built data visualizations using SVG elements\n",
                "\n",
                "### **Best Practices Demonstrated**\n",
                "- Error handling for network requests and data parsing\n",
                "- Code organization with utility functions\n",
                "- Configuration management with environment variables\n",
                "- Data validation and cleaning\n",
                "- Multiple visualization approaches for different insights\n",
                "\n",
                "### **Next Steps**\n",
                "- Experiment with different XPath selectors for other websites\n",
                "- Try scraping different data sources\n",
                "- Create more complex SVG visualizations\n",
                "- Combine multiple data sources for richer analysis"
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3ab4c01a",
            "metadata": {},
            "source": [
                "# Clean up - list all files created during this session\n",
                "created_files = []\n",
                "possible_files = ['test_page.html', 'tides_processed.csv (removed)', 'irregular-polygon.svg', \n",
                "                 'geometric-shapes.svg', 'sample-chart.svg'] + \\\n",
                "                [f'city-{i}.json' for i in range(1, 10)]\n",
                "\n",
                "for filename in possible_files:\n",
                "    if os.path.exists(filename):\n",
                "        created_files.append(filename)\n",
                "\n",
                "print(\"Files created during this session:\")\n",
                "for file in created_files:\n",
                "    file_size = os.path.getsize(file)\n",
                "    print(f\"  {file} ({file_size} bytes)\")\n",
                "\n",
                "print(f\"\\nTotal files created: {len(created_files)}\")\n",
                "print(\"\\nWeek 02 notebook completed successfully! \ud83c\udf89\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}